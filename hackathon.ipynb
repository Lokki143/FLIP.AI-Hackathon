{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic preprocessing of data\n",
    "train_data=pd.read_excel('Train_dataset.xlsx')\n",
    "test_data=pd.read_excel('Test_dataset.xlsx')\n",
    "\n",
    "train_x=train_data.iloc[:,:-1].values\n",
    "\n",
    "train_y=train_data.iloc[:,-1].values\n",
    "\n",
    "x_test=test_data.iloc[:,:].values\n",
    "original_test=x_test\n",
    "\n",
    "\n",
    "train_x=np.delete(train_x,[7,8,9,665],0)\n",
    "train_x=np.delete(train_x,[0,1,2,4],1)\n",
    "train_y=np.delete(train_y,[7,8,9,665],0)\n",
    "\n",
    "x_test=np.delete(x_test,[0,1,2,4],1)\n",
    "\n",
    "df=pd.DataFrame(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling the missing values of SWM column in test set\n",
    "for i in range(len(x_test[:,4])):\n",
    "    \n",
    "    if(type(x_test[:,4][i])==str):\n",
    "        continue\n",
    "    else:\n",
    "        x_test[:,4][i]=\"LOW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder_X = LabelEncoder()\n",
    "train_x[:,4] = labelencoder_X.fit_transform(train_x[:, 4])\n",
    "x_test[:,4]=labelencoder_X.fit_transform(x_test[:,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the nan entries of columns(with less missing values) of training set with median of values\n",
    "impute=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "\n",
    "impute=impute.fit(train_x[:,0:7])\n",
    "train_x[:,0:7]=impute.transform(train_x[:,0:7])\n",
    "\n",
    "impute=impute.fit(train_x[:,(9,10)])\n",
    "train_x[:,(9,10)]=impute.transform(train_x[:,(9,10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling the nan entries of columns of training set with median of values\n",
    "\n",
    "impute_test=SimpleImputer(missing_values=np.nan,strategy='median')\n",
    "impute=impute.fit(x_test)\n",
    "x_test=impute.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now using linear regression for filling the reamaining missing values in the dataset\n",
    "y=train_x[:,8]\n",
    "x=train_x[:,0]\n",
    "\n",
    "y=list([y[i] for i in range(len(y)) if(~np.isnan(y[i]))])\n",
    "x=list([x[i] for i in range(len(y)) if(~np.isnan(y[i]))])\n",
    "\n",
    "l=len(y)\n",
    "l1=len(x)\n",
    "\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "\n",
    "x=np.reshape(x,(l1,1))\n",
    "y=np.reshape(y,(l,1))\n",
    "\n",
    "y1=train_x[:,7]\n",
    "x1=train_x[:,3]\n",
    "\n",
    "y1=list([y1[i] for i in range(len(y1)) if(~np.isnan(y1[i]))])\n",
    "x1=list([x1[i] for i in range(len(y1)) if(~np.isnan(y1[i]))])\n",
    "\n",
    "l=len(y1)\n",
    "l1=len(x1)\n",
    "\n",
    "x1=np.array(x1)\n",
    "y1=np.array(y1)\n",
    "\n",
    "x1=np.reshape(x1,(l1,1))\n",
    "y1=np.reshape(y1,(l,1))\n",
    "final=np.zeros((783,))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x, y)\n",
    "\n",
    "for i in range(783):\n",
    "    if(np.isnan(train_x[:,8][i])):\n",
    "        z=train_x[:,0][i]\n",
    "        final[i]=regressor.predict([[z]])\n",
    "    else:\n",
    "        final[i]=train_x[:,8][i]\n",
    "\n",
    "train_x[:,8]=final\n",
    "\n",
    "\n",
    "regressor1 = LinearRegression()\n",
    "regressor1.fit(x1, y1)\n",
    "\n",
    "for i in range(783):\n",
    "    if(np.isnan(train_x[:,7][i])):\n",
    "        z=train_x[:,3][i]\n",
    "        final[i]=regressor.predict([[z]])\n",
    "    else:\n",
    "        final[i]=train_x[:,7][i]\n",
    "\n",
    "train_x[:,7]=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data using Standard Scalar\n",
    "sc_x = StandardScaler()\n",
    "\n",
    "train_x=sc_x.fit_transform(train_x)\n",
    "x_test=sc_x.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(128,input_dim=11,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "optimizer=keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ba3401b080>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,validation_split=0.2,epochs=1000,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('hackathon.csv', mode='w') as hackathon_file:\n",
    "    hackathon_writer = csv.writer(hackathon_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    hackathon_writer.writerow([\"City\",\"Covid cases\"])\n",
    "    for i in range(len(x_test)):\n",
    "      hackathon_writer.writerow([original_test[i,0],y_pred[i]])\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
